{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "231_demo1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Kristytiki/Neural-Network/blob/master/231_tensorflow_basic.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BupG2yql_jHa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 231 Project 0"
      ]
    },
    {
      "metadata": {
        "id": "pGZC3oHBiiI_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Today\n",
        "- (1) Assignment\n",
        "- (2) TensorFlow\n",
        "- (3) GPU\n",
        "- (4) PyTorch vs. TensorFlow"
      ]
    },
    {
      "metadata": {
        "id": "XVjSwH9rlWXK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Static shape**"
      ]
    },
    {
      "metadata": {
        "id": "hL1kUXpfiav2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8ef480d4-8575-4389-8436-8bee17d7260f"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "x = tf.placeholder(dtype=tf.float32, shape=[64, 10])\n",
        "print(x.shape)\n",
        "x_val = np.zeros([64, 10])\n",
        "\n",
        "with tf.Session() as sess:\n",
        "  print(tf.shape(x).eval(feed_dict={x: x_val}))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 10)\n",
            "[64 10]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lzluv2valarO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Dynamic shape**"
      ]
    },
    {
      "metadata": {
        "id": "VReXhmW5lP5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "62c1f742-9a50-420e-dc1d-dc4e4684f370"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "with tf.Session():\n",
        "  x = tf.placeholder(dtype=tf.float32, shape=[4])\n",
        "  print(x.get_shape())\n",
        "  y, _ = tf.unique(x)\n",
        "  print(y.get_shape())\n",
        "  print(y.eval(feed_dict={x: [0,1,2,3]}).shape)\n",
        "  print(y.eval(feed_dict={x: [0,0,0,0]}).shape)\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4,)\n",
            "(?,)\n",
            "(4,)\n",
            "(1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LEnY_STpmEJn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3aa84b09-b51e-47cf-a321-4ec68eaa04a4"
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(dtype=tf.float32, shape=(None, 10, 5))\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "x2 = tf.reshape(x, (tf.shape(x)[0], -1))\n",
        "\n",
        "x2_shape = tf.shape(x2)\n",
        "with tf.Session():\n",
        "  print(x2_shape.eval(feed_dict={x: np.zeros((32, 10, 5))}))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(?, 10, 5)\n",
            "[32 50]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JeGkULaonEwV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**tf.Print()**"
      ]
    },
    {
      "metadata": {
        "id": "ELoUR7pSEApJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.placeholder(tf.int32, shape=[4])\n",
        "y = tf.Print(x, [tf.shape(x)], message='x=', summarize=4)\n",
        "\n",
        "with tf.Session():\n",
        "  y.eval(feed_dict={x:[0,1,2,3]})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZ_JCMMsEE22",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "No output in Colab. Should work in PyCharm. Remedy below."
      ]
    },
    {
      "metadata": {
        "id": "75xyP1ffnEbg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "outputId": "5a1016c7-7f54-4232-c4d2-bb4160f0ef9e"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "response = urllib.request.urlopen('https://raw.githubusercontent.com/enijkamp/tensorflow-snippets/master/memory_util.py')\n",
        "open('memory_util.py', 'wb').write(response.read())\n",
        "import memory_util\n",
        "\n",
        "x = tf.placeholder(tf.int32, shape=[4])\n",
        "y = tf.Print(x, [tf.shape(x)], message='x=', summarize=4)\n",
        "\n",
        "with memory_util.capture_stderr() as stderr:\n",
        "  with tf.Session():\n",
        "    y.eval(feed_dict={x:[0,1,2,3]})\n",
        "                      \n",
        "print(stderr.getvalue())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-10 03:40:46.816072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-10 03:40:46.816146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-10 03:40:46.816166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-10 03:40:46.816183: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-10 03:40:46.816442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9911 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "x=[4]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4ug0Wk--oZ5E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convolution**"
      ]
    },
    {
      "metadata": {
        "id": "Vv9hQsXSoeSB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "36958807-6a38-41e5-82a9-ce684f4cd496"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "conv_w1 = tf.Variable(tf.zeros([5, 5, 3, 32]))\n",
        "conv_b1 = tf.Variable(tf.zeros(32,))\n",
        "\n",
        "# N H W C\n",
        "x = tf.placeholder(dtype=tf.float32, shape=[64, 32, 32, 3])\n",
        "\n",
        "# block 1\n",
        "x1_1_pad = tf.pad(x, [[0, 0], [2, 2], [2, 2], [0, 0]], mode='CONSTANT', constant_values=0)\n",
        "x1_2_conv = tf.nn.conv2d(x1_1_pad, conv_w1, [1, 1, 1, 1], padding='VALID') + conv_b1\n",
        "x1_3_pad = tf.pad(x1_2_conv, [[0, 0], [1, 1], [1, 1], [0, 0]], mode='CONSTANT', constant_values=0)\n",
        "x1_4_pool = tf.nn.max_pool(x1_3_pad, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "x1_5_relu = tf.nn.relu(x1_4_pool)\n",
        "\n",
        "x1_5_relu = tf.Print(x1_5_relu, [tf.shape(x1_5_relu)], summarize=4)\n",
        "\n",
        "with memory_util.capture_stderr() as stderr:\n",
        "  with tf.Session():\n",
        "    tf.initializers.global_variables().run()\n",
        "    x1_5_relu.eval(feed_dict={x: np.zeros([64, 32, 32, 3])})\n",
        "\n",
        "print(stderr.getvalue()) "
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018-10-10 02:39:40.702528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1490] Adding visible gpu devices: 0\n",
            "2018-10-10 02:39:40.702593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2018-10-10 02:39:40.702613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977]      0 \n",
            "2018-10-10 02:39:40.702628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990] 0:   N \n",
            "2018-10-10 02:39:40.702927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9911 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "[64 16 16 32]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8pYDyhZApygk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Convolution (2)**"
      ]
    },
    {
      "metadata": {
        "id": "8m0MeqCIp7SS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "input 7x7\n",
        "\n",
        "filter 3x3\n",
        "\n",
        "stride 1\n",
        "\n",
        "padding 0\n",
        "\n",
        "(W-F+2P)/S+1"
      ]
    },
    {
      "metadata": {
        "id": "3OeZYYvrp5FL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "76a9a13e-9372-4ed3-c875-01ca5c42abb0"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "W = 7\n",
        "F = 3\n",
        "P = 0\n",
        "S = 1\n",
        "\n",
        "x_in = tf.placeholder(dtype=tf.float32, shape=[1, W, W, 1])\n",
        "x_out = tf.nn.conv2d(x_in, filter=tf.zeros([F, F, 1, 1]), strides=[1, S, S, 1], padding='VALID')\n",
        "x_out_shape = tf.shape(x_out)\n",
        "\n",
        "with tf.Session():\n",
        "  print(x_out_shape.eval(feed_dict={x_in: np.zeros([1, W, W, 1])}))\n",
        "  \n",
        "  assert (x_out_shape.eval(feed_dict={x_in: np.zeros([1, W, W, 1])}) == [1, 5, 5, 1]).all()\n",
        "\n",
        "  print((W-F+2*P)/S+1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 5 5 1]\n",
            "5.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4Nj4pMeyrC_1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Padding**"
      ]
    },
    {
      "metadata": {
        "id": "tOnPAXRUrBTD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1., 2., 3., 4., 5., 6.])\n",
        "x = tf.reshape(x, [1, 2, 3, 1])\n",
        "\n",
        "valid_pad = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
        "same_pad = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
        "\n",
        "assert valid_pad.get_shape() == [1,1,1,1]\n",
        "assert same_pad.get_shape() == [1,1,2,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i_HoPiKIroIg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = tf.constant([1., 2., 3., 4., 5., 6.])\n",
        "x = tf.reshape(x, [1, 2, 3, 1])\n",
        "\n",
        "valid_pad = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='VALID')\n",
        "same_pad = tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 1, 1, 1], padding='SAME')\n",
        "\n",
        "assert valid_pad.get_shape() == [1,1,2,1]\n",
        "assert same_pad.get_shape() == [1,2,3,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_Qz59-5OsEDT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**GPU**"
      ]
    },
    {
      "metadata": {
        "id": "cgdvykVwBjmi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "For this collab notebook:\n",
        "\n",
        "Set Runtime -> Change runtime type to \"GPU\""
      ]
    },
    {
      "metadata": {
        "id": "xFsOsa5CsFj8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23ae5c25-0cf1-4da6-ba00-a782975b8ba7"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)\n",
        "assert device_name == '/device:GPU:0'"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "b6Il9ImFAxcq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "- Copy and paste your solution here\n",
        "- set USE_GPU=True\n",
        "- Run on GPU which is about 40x faster"
      ]
    },
    {
      "metadata": {
        "id": "KqC744mHBWKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "6f8ab783-df23-43b1-b300-0671e36bfabf"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 13557701016319533664\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 10392928256\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 12930440421430216492\n",
            "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Bu4zEfzMs670",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**TF versus PyTorch**"
      ]
    },
    {
      "metadata": {
        "id": "2amRTpEMBBgM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "TensorFlow:\n",
        "- funding by Google\n",
        "- static computational graph\n",
        "- \"Define and run\"\n",
        "- \"eager\" mode resembles PyTorch\n",
        "- static graph might be advantageous for production enviroments\n",
        "- TensorFlow 2.0 will resemble PyTorch\n",
        "  \n",
        "PyTorch:\n",
        "- funding by Facebook AI\n",
        "- dynamic computational graph\n",
        "- \"Define by run\"\n",
        "- debugging simplified\n",
        "- Google supports PyTorch 1.0 on GCE"
      ]
    },
    {
      "metadata": {
        "id": "O4gKIdx4_wd3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "x = tf.Variable(tf.ones((1, 1)))\n",
        "y = tf.pow(x, 2)\n",
        "print(y)\n",
        "\n",
        "\n",
        "# view in debugger -> symbolic\n",
        "g1 = tf.gradients(y, x)[0]\n",
        "\n",
        "with tf.Session():\n",
        "    tf.initializers.global_variables().run()\n",
        "    print(g1.eval())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fiXuVcbJAL3M",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(1, 1, requires_grad=True)\n",
        "y = x ** 2\n",
        "print(y)\n",
        "g1 = torch.autograd.grad(y, x)[0]\n",
        "print(g1)\n",
        "\n",
        "# view in debugger -> numpy\n",
        "g1_np = g1.cpu().numpy()\n",
        "\n",
        "x = torch.ones(1, 1, requires_grad=True)\n",
        "y = x ** 2\n",
        "y.backward()\n",
        "g2 = x.grad\n",
        "print(g2)\n",
        "\n",
        "assert g1 == g2"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}